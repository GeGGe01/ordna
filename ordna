#!/usr/bin/env bash
#
#   ordna SOURCE... DEST {-m | -c} [OPTIONS]
#
# Examples:
#   ordna file1.jpg file2.png outputdir -m
#   ordna dir1 dir2 outputdir -c --from 2023-01-01 --to 2023-12-31 -x
#   ordna *.jpg outputdir -m --dry-run
#   ordna dirs* outputdir -c -x --from 2025-05-21 --to 2025-07-21 --dry-run
#
# Notes:
#   - SOURCE can be one or more files or directories; directories are expanded recursively.
#   - DEST is always the last argument and must be a directory.
#   - Use -m/--move to move files, or -c/--copy to copy them.
#   - --from and --to specify date ranges (YYYY-mm-dd).
#   - Additional flags (-x, --dry-run, --merge) modify behavior as described in help.

set -euo pipefail

# Defaults
SOURCES=()
DEST=""
MODE=""
FROM_DATE=""
TO_DATE=""
SORT_EXT=false
DRYRUN=false
MERGE=false

help() {
    cat <<EOF
Usage: ordna SOURCE... DEST {-m | -c} [OPTIONS]

Sources:
  One or more files or directories to be processed (directories are expanded to their files).
  The last positional argument is treated as the destination directory.

Required:
  -m, --move             Move files
  -c, --copy             Copy files

Options:
  --from DATE            Start date (YYYY-mm-dd)
  --to DATE              End date (YYYY-mm-dd)
  -x, --ext              Sort into subfolders by file extension
  --dry-run              Show what would be done without making changes
  --merge                Merge / overwrite (default: smart unique naming)
  -h, --help             Show this help

Dependencies:
  exiftool, file, sha256sum (or sha1sum/md5sum)
EOF
    exit 0
}

die() {
    echo "Error: $1" >&2
    echo "Try 'ordna --help' for usage." >&2
    exit 2
}

# --- Robust option parsing via getopt (short+long) ---
# Short: -m -c -x -h ; Long: --move --copy --ext --help --from= --to= --dry-run --merge
PARSED=$(getopt -o mcxh -l move,copy,ext,help,from:,to:,dry-run,merge -- "$@") || die "invalid options"
eval set -- "$PARSED"

while true; do
    case "$1" in
        -m|--move) MODE="move"; shift ;;
        -c|--copy) MODE="copy"; shift ;;
        --from)    FROM_DATE="$2"; shift 2 ;;
        --to)      TO_DATE="$2"; shift 2 ;;
        -x|--ext)  SORT_EXT=true; shift ;;
        --dry-run) DRYRUN=true; shift ;;
        --merge)   MERGE=true; shift ;;
        -h|--help) help ;;
        --) shift; break ;;
        *) die "unexpected parser state '$1'" ;;
    esac
done

# Remaining are positionals: at least 2 (SOURCES..., DEST)
if [[ $# -lt 2 ]]; then
    die "must specify at least one source and one destination"
fi

# Split DEST (last) and SOURCES (rest)
DEST="${@: -1}"
SOURCES=("${@:1:$(($#-1))}")

# Validate mode
[[ -n "$MODE" ]] || die "must specify -m or -c"

# Validate required dependencies
for dep in exiftool file sha256sum; do
    command -v "$dep" >/dev/null 2>&1 || die "missing dependency: $dep"
done

# Validate dates (format + range)
if [[ -n "$FROM_DATE" ]]; then
    date -d "$FROM_DATE" +%Y-%m-%d >/dev/null 2>&1 || die "invalid --from date (YYYY-mm-dd)"
fi
if [[ -n "$TO_DATE" ]]; then
    date -d "$TO_DATE" +%Y-%m-%d >/dev/null 2>&1 || die "invalid --to date (YYYY-mm-dd)"
fi
if [[ -n "$FROM_DATE" && -n "$TO_DATE" ]]; then
    [[ "$(date -d "$FROM_DATE" +%s)" -le "$(date -d "$TO_DATE" +%s)" ]] || die "--from later than --to"
fi

# --- Helpers ---
log()   { printf '%s\n' "$*"; }
quote() { printf '"%s"' "$1"; }

# Prefer EXIF DateTimeOriginal/CreateDate/ModifyDate via exiftool
get_epoch() {
    local f="$1" t=""
    t=$(exiftool -s3 -n -DateTimeOriginal# -- "$f" 2>/dev/null || true)
    [[ -z "$t" ]] && t=$(exiftool -s3 -n -CreateDate# -- "$f" 2>/dev/null || true)
    [[ -z "$t" ]] && t=$(exiftool -s3 -n -ModifyDate# -- "$f" 2>/dev/null || true)
    [[ -z "$t" ]] && t=$(stat -c %Y -- "$f" 2>/dev/null || echo 0)
    printf '%s' "${t:-0}"
}

in_range() {
    # If no dates provided, consider everything in range
    local t="$1"
    if [[ -z "$FROM_DATE" && -z "$TO_DATE" ]]; then
        return 0
    fi
    local from=0 to=32503680000 # year 3000
    [[ -n "$FROM_DATE" ]] && from=$(date -d "$FROM_DATE 00:00:00" +%s)
    [[ -n "$TO_DATE"   ]] && to=$(date -d "$TO_DATE 23:59:59" +%s)
    [[ "$t" -ge "$from" && "$t" -le "$to" ]]
}

get_ext() {
    local f="$1" base ext mime
    base=$(basename -- "$f")

    # 1) Content-based via `file --extension`
    ext=$(file --brief --extension -- "$f" 2>/dev/null | cut -d/ -f1 | tr '[:upper:]' '[:lower:]')

    # 2) If unknown/empty, fall back to name-based extension
    if [[ -z "$ext" || "$ext" == "???" || "$ext" == "??? " ]]; then
        ext="${base##*.}"
        [[ "$ext" == "$base" ]] && ext=""
        ext="${ext,,}"
    fi

    # 3) If still unknown, try MIME-type + heuristics
    if [[ -z "$ext" || "$ext" == "???" || "$ext" == "??? " || "$ext" == "" ]]; then
        mime=$(file -b --mime-type -- "$f" 2>/dev/null || true)
        case "$mime" in
            application/xml|text/xml) ext="xml" ;;
            application/json|text/json) ext="json" ;;
            text/plain)
                # Peek first bytes for XML prolog
                if head -c 100 -- "$f" 2>/dev/null | grep -qi '^\s*<\?xml'; then
                    ext="xml"
                else
                    ext="txt"
                fi
                ;;
            application/zip)
                # Office Open XML are zip containers â€“ infer from name if possible
                [[ "$base" == *.docx ]] && ext="docx"
                [[ "$base" == *.xlsx ]] && ext="xlsx"
                [[ "$base" == *.pptx ]] && ext="pptx"
                [[ -z "$ext" ]] && ext="zip"
                ;;
            *)
                : # leave ext as-is
                ;;
        esac
    fi

    [[ -z "$ext" ]] && ext="unknown"
    printf '%s' "$ext"
}

# Hash helper (sha256 required)
hash_of() {
    local f="$1"
    sha256sum -- "$f" 2>/dev/null | awk '{print $1}'
}

# Ensure destination base exists
mkdir -p -- "$DEST"

# Collect files from SOURCES (files or directories)
collect_files() {
    local files=()
    local p
    for p in "${SOURCES[@]}"; do
        if [[ -f "$p" ]]; then
            files+=("$p")
        elif [[ -d "$p" ]]; then
            while IFS= read -r -d '' f; do
                files+=("$f")
            done < <(find "$p" -type f -print0)
        else
            log "Warning: source not found or unsupported: $p" >&2
        fi
    done
    printf '%s\n' "${files[@]}"
}

# Decide target directory for a given file
# Returns path via echo
target_dir_for() {
    local f="$1" epoch bucket dir
    epoch=$(get_epoch "$f") || epoch=0
    if in_range "$epoch"; then bucket="range"; else bucket="scrap"; fi
    dir="$DEST/$bucket"
    if $SORT_EXT; then
        dir="$dir/$(get_ext "$f")"
    fi
    printf '%s' "$dir"
}

# Make a unique path if needed (content-aware). Returns final path via echo.
unique_path() {
    local dst="$1" src="$2" base ext hash cand n=1
    if [[ -e "$dst" ]]; then
        # If same content, keep existing by signaling "skip"
        local h_src h_dst
        h_src=$(hash_of "$src")
        h_dst=$(hash_of "$dst")
        if [[ "$h_src" == "$h_dst" ]]; then
            echo "__SKIP_IDENTICAL__"; return 0
        fi
        base=$(basename -- "$dst")
        ext=""; [[ "$base" == *.* ]] && ext=".${base##*.}" && base="${base%.*}"
        hash=$(hash_of "$src" | cut -c1-12)
        cand="$(dirname -- "$dst")/${base}_$hash$ext"
        # Ensure uniqueness if even that exists
        while [[ -e "$cand" ]]; do
            n=$((n+1))
            cand="$(dirname -- "$dst")/${base}_$hash-$n$ext"
        done
        echo "$cand"
    else
        echo "$dst"
    fi
}

# Copy/move a single file to its computed target, honoring merge/dry-run and smart naming
apply_action() {
    local src="$1" tdir tpath final action
    tdir=$(target_dir_for "$src")
    mkdir -p -- "$tdir"
    tpath="$tdir/$(basename -- "$src")"

    if $MERGE; then
        final="$tpath"
    else
        final=$(unique_path "$tpath" "$src")
        if [[ "$final" == "__SKIP_IDENTICAL__" ]]; then
            log "skip (identical): $tpath"
            return 0
        fi
    fi

    if [[ "$MODE" == "move" ]]; then
        action=(mv -- "$src" "$final")
    else
        action=(cp -p -- "$src" "$final")
    fi

    if $DRYRUN; then
        printf 'DRY: %q ' "${action[@]}"; echo
    else
        "${action[@]}"
    fi
}

# Shared processing over a list of files
process() {
    local f
    while IFS= read -r f; do
        [[ -n "$f" ]] || continue
        apply_action "$f"
    done
}

# Resolve mode and dispatch to processing
dispatch() {
    collect_files | process
}

# Execute
dispatch

