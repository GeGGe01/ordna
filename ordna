#!/usr/bin/env bash
#
#   ordna SOURCE... DEST {-m | -c} [OPTIONS]
#
# Examples:
#   ordna file1.jpg file2.png outputdir -m
#   ordna dir1 dir2 outputdir -c --from 2023-01-01 --to 2023-12-31 -x
#   ordna *.jpg outputdir -m --dry-run
#   ordna dirs* outputdir -c -x --from 2025-05-21 --to 2025-07-21 --dry-run
#
# Notes:
#   - SOURCE can be one or more files or directories; directories are expanded recursively.
#   - DEST is always the last argument and must be a directory.
#   - Use -m/--move to move files, or -c/--copy to copy them.
#   - --from and --to specify date ranges (YYYY-mm-dd).
#   - Additional flags (-x, --dry-run, --merge) modify behavior as described in help.

set -euo pipefail

# Defaults
SOURCES=()
FILES=()            # collected files (array; NUL-safe)
DEST=""
MODE=""
FROM_DATE=""
TO_DATE=""
SORT_EXT=false
DRYRUN=false
MERGE=false
STRICT_EXT=false    # if true, MIME sniffing is enabled for unknown extensions

help() {
    cat <<EOF
Usage: ordna SOURCE... DEST {-m | -c} [OPTIONS]

Sources:
  One or more files or directories to be processed (directories are expanded to their files).
  The last positional argument is treated as the destination directory.

Required:
  -m, --move             Move files
  -c, --copy             Copy files

Options:
  --from DATE            Start date (YYYY-mm-dd)
  --to DATE              End date (YYYY-mm-dd)
  -x, --ext              Sort into subfolders by file extension
  --strict-ext           When extension unknown, sniff MIME (slower but more accurate)
  --dry-run              Show what would be done without making changes
  --merge                Merge / overwrite (default: smart unique naming)
  -h, --help             Show this help

Dependencies:
  exiftool, file, sha256sum (or sha1sum/md5sum)

Portability:
  Requires enhanced getopt (util-linux) and a date implementation with -d support.
  Behavior-based detection is performed and a clear error is shown if missing.
EOF
    exit 0
}

die() {
    echo "Error: $1" >&2
    echo "Try 'ordna --help' for usage." >&2
    exit 2
}

# --- Behavior checks (portable) ---
# getopt: util-linux variant returns exit code 4 for --test
getopt --test >/dev/null 2>&1 || true
if [[ $? -ne 4 ]]; then
    die "requires enhanced getopt (util-linux); found BSD/limited variant"
fi
# date: must support GNU-compatible -d parsing
if ! date -d '1970-01-01 00:00:00 +0000' +%s >/dev/null 2>&1; then
    die "requires date -d support (GNU date or compatible)"
fi

# --- Robust option parsing via getopt (short+long) ---
PARSED=$(getopt -o mcxh -l move,copy,ext,strict-ext,help,from:,to:,dry-run,merge -- "$@") || die "invalid options"
eval set -- "$PARSED"

while true; do
    case "$1" in
        -m|--move) MODE="move"; shift ;;
        -c|--copy) MODE="copy"; shift ;;
        --from)    FROM_DATE="$2"; shift 2 ;;
        --to)      TO_DATE="$2"; shift 2 ;;
        -x|--ext)  SORT_EXT=true; shift ;;
        --strict-ext) STRICT_EXT=true; shift ;;
        --dry-run) DRYRUN=true; shift ;;
        --merge)   MERGE=true; shift ;;
        -h|--help) help ;;
        --) shift; break ;;
        *) die "unexpected parser state '$1'" ;;
    esac
done

# Remaining are positionals: at least 2 (SOURCES..., DEST)
if [[ $# -lt 2 ]]; then
    die "must specify at least one source and one destination"
fi

# Split DEST (last) and SOURCES (rest)
DEST="${@: -1}"
SOURCES=("${@:1:$(($#-1))}")

# Validate mode
[[ -n "$MODE" ]] || die "must specify -m or -c"

# Validate required dependencies
for dep in exiftool file sha256sum; do
    command -v "$dep" >/dev/null 2>&1 || die "missing dependency: $dep"
done

# Validate dates (format + range)
if [[ -n "$FROM_DATE" ]]; then
    date -d "$FROM_DATE" +%Y-%m-%d >/dev/null 2>&1 || die "invalid --from date (YYYY-mm-dd)"
fi
if [[ -n "$TO_DATE" ]]; then
    date -d "$TO_DATE" +%Y-%m-%d >/dev/null 2>&1 || die "invalid --to date (YYYY-mm-dd)"
fi
if [[ -n "$FROM_DATE" && -n "$TO_DATE" ]]; then
    [[ "$(date -d "$FROM_DATE" +%s)" -le "$(date -d "$TO_DATE" +%s)" ]] || die "--from later than --to"
fi

# --- Helpers ---
log()   { printf '%s\n' "$*"; }
quote() { printf '"%s"' "$1"; }

# Prefer EXIF DateTimeOriginal/CreateDate/ModifyDate via exiftool
get_epoch() {
    local f="$1" t=""

    # Batch exiftool call to reduce process overhead
    local info
    info=$(exiftool -s3 -n -DateTimeOriginal# -CreateDate# -ModifyDate# -- "$f" 2>/dev/null || true)

    while IFS=$'\n' read -r line; do
        if [[ "$line" =~ ^[0-9]+$ && -n "$line" ]]; then
            printf '%s' "$line"
            return
        fi
    done <<< "$info"

    # Try formatted strings like "2024:03:01 10:40:42+01:00"
    for tag in DateTimeOriginal CreateDate ModifyDate; do
        t=$(exiftool -s3 -api QuickTimeUTC=1 -$tag -- "$f" 2>/dev/null || true)
        if [[ -n "$t" ]]; then
            t=${t/:/-}; t=${t/:/-}
            if epoch=$(date -d "$t" +%s 2>/dev/null); then
                printf '%s' "$epoch"
                return
            fi
        fi
    done

    # Fallback to mtime
    t=$(stat -c %Y -- "$f" 2>/dev/null || echo 0)
    printf '%s' "${t:-0}"
}

in_range() {
    local t="$1"
    if [[ -z "$FROM_DATE" && -z "$TO_DATE" ]]; then
        return 0
    fi
    local from=0 to=32503680000 # year 3000
    [[ -n "$FROM_DATE" ]] && from=$(date -d "$FROM_DATE 00:00:00" +%s)
    [[ -n "$TO_DATE"   ]] && to=$(date -d "$TO_DATE 23:59:59" +%s)
    [[ "$t" -ge "$from" && "$t" -le "$to" ]]
}

get_ext() {
    # Cost model: fast path first (name-based), only sniff MIME if requested or unknown
    local f="$1" base ext mime
    base=$(basename -- "$f")

    # 1) O(1) filename-based decision
    ext="${base##*.}"
    [[ "$ext" == "$base" ]] && ext=""
    ext="${ext,,}"

    # 2) If unknown/empty OR strict mode requested, consult `file`
    if [[ -z "$ext" || "$ext" == "" || "$STRICT_EXT" == true ]]; then
        # Try content-based via `file --extension` (cheap-ish)
        local fext
        fext=$(file --brief --extension -- "$f" 2>/dev/null | cut -d/ -f1 | tr '[:upper:]' '[:lower:]')
        if [[ -n "$fext" && "$fext" != "???" && "$fext" != "??? " ]]; then
            ext="$fext"
        elif [[ "$STRICT_EXT" == true ]]; then
            # MIME sniff only in strict mode (expensive)
            mime=$(file -b --mime-type -- "$f" 2>/dev/null || true)
            case "$mime" in
                application/xml|text/xml) ext="xml" ;;
                application/json|text/json) ext="json" ;;
                text/plain)
                    if head -c 100 -- "$f" 2>/dev/null | grep -qi '^\s*<\?xml'; then
                        ext="xml"
                    else
                        ext="txt"
                    fi
                    ;;
                application/zip)
                    [[ "$base" == *.docx ]] && ext="docx"
                    [[ "$base" == *.xlsx ]] && ext="xlsx"
                    [[ "$base" == *.pptx ]] && ext="pptx"
                    [[ -z "$ext" ]] && ext="zip"
                    ;;
                *) : ;;
            esac
        fi
    fi

    [[ -z "$ext" ]] && ext="unknown"
    printf '%s' "$ext"
}

hash_of() {
    local f="$1"
    sha256sum -- "$f" 2>/dev/null | awk '{print $1}'
}

mkdir -p -- "$DEST"

collect_files() {
    FILES=()
    local p
    for p in "${SOURCES[@]}"; do
        if [[ -f "$p" ]]; then
            FILES+=("$p")
        elif [[ -d "$p" ]]; then
            # NUL-safe collection
            while IFS= read -r -d '' f; do
                FILES+=("$f")
            done < <(find "$p" -type f -print0)
        else
            log "Warning: source not found or unsupported: $p" >&2
        fi
    done
}

target_dir_for() {
    local f="$1" epoch bucket dir
    epoch=$(get_epoch "$f") || epoch=0
    if in_range "$epoch"; then bucket="range"; else bucket="scrap"; fi
    dir="$DEST/$bucket"
    if $SORT_EXT; then
        dir="$dir/$(get_ext "$f")"
    fi
    printf '%s' "$dir"
}

unique_path() {
    local dst="$1" src="$2" base ext hash cand n=1
    if [[ -e "$dst" ]]; then
        local h_src h_dst
        h_src=$(hash_of "$src")
        h_dst=$(hash_of "$dst")
        if [[ "$h_src" == "$h_dst" ]]; then
            echo "__SKIP_IDENTICAL__"; return 0
        fi
        base=$(basename -- "$dst")
        ext=""; [[ "$base" == *.* ]] && ext=".${base##*.}" && base="${base%.*}"
        hash=$(hash_of "$src" | cut -c1-12)
        cand="$(dirname -- "$dst")/${base}_$hash$ext"
        while [[ -e "$cand" ]]; do
            n=$((n+1))
            cand="$(dirname -- "$dst")/${base}_$hash-$n$ext"
        done
        echo "$cand"
    else
        echo "$dst"
    fi
}

apply_action() {
    local src="$1" tdir tpath final action
    tdir=$(target_dir_for "$src")
    mkdir -p -- "$tdir"
    tpath="$tdir/$(basename -- "$src")"

    if $MERGE; then
        final="$tpath"
    else
        final=$(unique_path "$tpath" "$src")
        if [[ "$final" == "__SKIP_IDENTICAL__" ]]; then
            log "skip (identical): $tpath"
            return 0
        fi
    fi

    if [[ "$MODE" == "move" ]]; then
        action=(mv -- "$src" "$final")
    else
        action=(cp -p -- "$src" "$final")
    fi

    if $DRYRUN; then
        printf 'DRY: '; printf '%q ' "${action[@]}"; echo
    else
        "${action[@]}"
    fi
}

process() {
    local f
    for f in "${FILES[@]}"; do
        apply_action "$f"
    done
}

dispatch() {
    collect_files
    process
}

dispatch

